{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"header\"><p style=\"color:#3364ff; text-align:center; font-weight:bold; font-family:verdana; font-size:25px;\">Image Recognition</p></div>\n",
    "\n",
    "[licenseBDG]: https://img.shields.io/badge/License-CC-orange?style=plastic\n",
    "[license]: https://creativecommons.org/licenses/by-nc-sa/3.0/deed.en\n",
    "\n",
    "[mywebsiteBDG]:https://img.shields.io/badge/website-jaorduz.github.io-0abeeb?style=plastic\n",
    "[mywebsite]: https://jaorduz.github.io/\n",
    "\n",
    "[mygithubBDG-jaorduz]: https://img.shields.io/badge/jaorduz-repos-blue?logo=github&label=jaorduz&style=plastic\n",
    "[mygithub-jaorduz]: https://github.com/jaorduz/\n",
    "\n",
    "[mygithubBDG-jaorduc]: https://img.shields.io/badge/jaorduc-repos-blue?logo=github&label=jaorduc&style=plastic \n",
    "[mygithub-jaorduc]: https://github.com/jaorduc/\n",
    "\n",
    "[myXprofileBDG]: https://img.shields.io/static/v1?label=Follow&message=jaorduc&color=2ea44f&style=plastic&logo=X&logoColor=black\n",
    "[myXprofile]:https://twitter.com/jaorduc\n",
    "\n",
    "\n",
    "[![website - jaorduz.github.io][mywebsiteBDG]][mywebsite]\n",
    "[![Github][mygithubBDG-jaorduz]][mygithub-jaorduz]\n",
    "[![Github][mygithubBDG-jaorduc]][mygithub-jaorduc]\n",
    "[![Follow @jaorduc][myXprofileBDG]][myXprofile]\n",
    "[![CC License][licenseBDG]][license]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'people.jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mface_recognition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_image_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpeople.jpeg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m face_locations \u001b[38;5;241m=\u001b[39m face_recognition\u001b[38;5;241m.\u001b[39mface_locations(image)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/face_recognition/api.py:86\u001b[0m, in \u001b[0;36mload_image_file\u001b[0;34m(file, mode)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_image_file\u001b[39m(file, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     79\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m    Loads an image file (.jpg, .png, etc) into a numpy array\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    :return: image contents as numpy array\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[43mPIL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode:\n\u001b[1;32m     88\u001b[0m         im \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mconvert(mode)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/PIL/Image.py:3465\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3462\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(fp)\n\u001b[1;32m   3464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3465\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3466\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3467\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'people.jpeg'"
     ]
    }
   ],
   "source": [
    "image = face_recognition.load_image_file(\"people.jpg\")\n",
    "face_locations = face_recognition.face_locations(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(59, 80, 122, 17),\n",
       " (90, 510, 141, 458),\n",
       " (78, 354, 130, 302),\n",
       " (98, 439, 142, 395),\n",
       " (95, 204, 147, 152),\n",
       " (103, 266, 146, 223),\n",
       " (84, 129, 136, 78),\n",
       " (66, 591, 129, 529)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 1 face(s) in this photograph.\n",
      "A face is located at pixel location\n",
      "Top: 632, Left: 2387,\n",
      "Bottom: 1018, Right: 2772\n"
     ]
    }
   ],
   "source": [
    "print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
    "for face_location in face_locations:\n",
    "\n",
    "    # Print the location of each face in this image\n",
    "    top, right, bottom, left = face_location\n",
    "    print(\"A face is located at pixel location\\nTop: {}, Left: {},\\nBottom: {}, Right: {}\".format(top, left, bottom, right))\n",
    "\n",
    "    # You can access the actual face itself like this:\n",
    "    face_image = image[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "print(\"Python version\",sys.version);\n",
    "print(\"CV version:\",cv2.__version__)\n",
    "print(\"Face recognition version:\",face_recognition.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "[1] https://github.com/ageitgey/face_recognition\n",
    "\n",
    "[2] https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_picture.py\n",
    "\n",
    "[3] https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_picture_cnn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
